\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{titlesec}
\usepackage{url}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{siunitx}
\usepackage{booktabs}

\geometry{top=2cm, bottom=2cm, left=2cm, right=2cm}

\sisetup{
output-decimal-marker={,},
group-digits = false
}

\setlength{\parindent}{1.25cm}
\setlength{\parskip}{0pt}

\titleformat{\section}{\normalfont\Large\bfseries\centering}{\thesection.}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection.}{1em}{}

\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    frame=single,
    tabsize=4,
    showstringspaces=false,
    breaklines=true
}

\begin{document}

\begin{titlepage}
\begin{center}
\textbf{МИНИСТЕРСТВО НАУКИ И ВЫСШЕГО ОБРАЗОВАНИЯ РОССИЙСКОЙ ФЕДЕРАЦИИ} \\[0.5cm]
\textbf{Федеральное государственное автономное образовательное учреждение высшего образования} \\[0.5cm]
\textbf{«Национальный исследовательский Нижегородский государственный университет им. Н.И. Лобачевского»} \\[0.5cm]
Институт информационных технологий, математики и механики \\
\vfill
{\Large
\textbf{Отчёт по лабораторной работе на тему:} \\[0.5cm]
\textbf{Умножение разреженных матриц в формате CCS} \\
}
\vfill
\begin{flushright}
Выполнил: студент группы 3822Б1ПР4 \\
Коньков Иван \\
\vspace{1cm}
Преподаватель: \\
Сысоев А.В., доцент, кандидат технических наук \\
\end{flushright}
\vfill
Нижний Новгород \\
2025
\end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Введение}
Умножение разреженных матриц — ключевая операция в вычислительной математике, машинном обучении и физике. Формат хранения CCS (Column-Compressed Storage) оптимизирует работу с разреженными данными, минимизируя использование памяти. В работе исследуются пять реализаций алгоритма: последовательная, OpenMP, TBB, STL и MPI. Основная цель — сравнение стратегий распараллеливания и анализ их применимости для задач большой размерности.

\section{Постановка задачи}
Реализовать умножение матриц в формате CCS:
\[
C = A \times B,
\]
где \( A, B, C \) — разреженные матрицы. Требования к реализациям:
\begin{itemize}
\item Корректная работа с CCS-форматом (валидация структур данных).
\item Поддержка многопоточности и распределенных вычислений.
\item Обеспечение линейной масштабируемости на многопроцессорных системах.
\item Прохождение функциональных тестов (сравнение с эталоном) и нагрузочного тестирования.
\end{itemize}

\section{Детали алгоритма}
\subsection{Структура CCS}
\begin{itemize}
\item \texttt{values}: Массив ненулевых элементов, упорядоченный по столбцам.
\item \texttt{row\_indices}: Индексы строк для каждого элемента из \texttt{values}.
\item \texttt{col\_ptr}: Массив указателей на начало столбцов в \texttt{values}.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{ccs_example.png}
\caption{Пример матрицы 3x3 в CCS-формате}
\end{figure}

\subsection{Этапы умножения}
\begin{enumerate}
\item \textbf{Инициализация структур}: 
  - Создание хэш-таблицы для накопления результатов по столбцам матрицы \( C \).
  
\item \textbf{Обработка столбцов \( B \)}:
  - Для каждого столбца \( j \) матрицы \( B \):
  \begin{itemize}
  \item Найти ненулевые элементы в столбце \( B[:,j] \).
  \item Для каждого ненулевого элемента \( B[k,j] \):
    \begin{itemize}
    \item Выбрать столбец \( A[:,k] \).
    \item Умножить \( A[:,k] \) на \( B[k,j] \).
    \item Добавить результат в соответствующие позиции \( C[:,j] \).
    \end{itemize}
  \end{itemize}
  
\item \textbf{Сортировка и компрессия}:
  - Упорядочить элементы в каждом столбце \( C \) по строкам.
  - Построить \texttt{col\_ptr} для результирующей матрицы.
\end{enumerate}

\subsection{Оптимизации}
\begin{itemize}
\item \textbf{Локализация данных}: Кэширование часто используемых столбцов.
\item \textbf{Векторизация}: Использование SIMD-инструкций для умножения/сложения.
\item \textbf{Предвыделение памяти}: Избежание частых реаллокаций при построении \( C \).
\end{itemize}

\section{Реализации}
\subsection{OpenMP}
\begin{itemize}
\item Распределение столбцов \( B \) между потоками через \texttt{\#pragma omp for}.
\item Редукция частичных сумм с помощью \texttt{reduction(+:sum)}.
\item Динамическая балансировка нагрузки (\texttt{schedule(dynamic)}).
\end{itemize}

\begin{lstlisting}[language=C++]
#pragma omp parallel for reduction(+ : sum)
for (int col_b = 0; col_b < colsB; ++col_b) {
    std::unordered_map<int, double> column_result;
    // Обработка столбца
    #pragma omp critical
    {
        // Объединение результатов
    }
}
\end{lstlisting}

\subsection{TBB}
\begin{itemize}
\item Использование \texttt{tbb::concurrent\_unordered\_map} для потокобезопасного обновления.
\item Параллелизация через \texttt{tbb::parallel\_reduce} с автоматическим разделением диапазона.
\item Локальное кэширование генераторов случайных чисел для каждого потока.
\end{itemize}

\begin{lstlisting}[language=C++]
tbb::parallel_for(tbb::blocked_range<int>(0, colsB), [&](auto& range) {
    tbb::concurrent_unordered_map<int, double> local_map;
    for (int col_b = range.begin(); col_b < range.end(); ++col_b) {
        // Обработка столбца
    }
});
\end{lstlisting}

\subsection{STL}
\begin{itemize}
\item Ручное распределение задач через пул потоков (\texttt{std::thread}).
\item Использование \texttt{std::promise} и \texttt{std::future} для синхронизации.
\item Батчинговое выполнение: предвыделение блоков итераций для минимизации накладных расходов.
\end{itemize}

\begin{lstlisting}[language=C++]
std::vector<std::thread> threads;
for (int t = 0; t < num_threads; ++t) {
    threads.emplace_back([&] {
        // Обработка части данных
    });
}
for (auto& thread : threads) thread.join();
\end{lstlisting}

\subsection{MPI}
\begin{itemize}
\item Распределение столбцов \( B \) между MPI-процессами.
\item Сбор результатов через \texttt{boost::mpi::gather} с агрегацией на главном узле.
\item Гибридный подход: многопоточность внутри узлов через STL.
\end{itemize}

\begin{lstlisting}[language=C++]
boost::mpi::broadcast(world_, A_values, 0);
boost::mpi::gather(world_, local_C, global_C, 0);
\end{lstlisting}

\section{Методология тестирования}
\subsection{Инструменты}
\begin{itemize}
\item \textbf{Google Test}: Функциональные тесты (корректность умножения).
\item \textbf{Valgrind}: Проверка на утечки памяти и гонки данных.
\end{itemize}

\subsection{Параметры экспериментов}
\begin{itemize}
\item \textbf{Аппаратная платформа}: 
  \begin{itemize}
  \item CPU: Intel Core i5-12400F (6 ядер, 12 потоков).
  \item RAM: 32 GB DDR4.
  \end{itemize}
\item \textbf{Размер матриц}: 5000x5000 (разреженность 0.5\%).
\item \textbf{Метрики}: 
  \begin{itemize}
  \item Ускорение относительно последовательной версии.
  \item Эффективность использования ресурсов.
  \end{itemize}
\end{itemize}

\section{Результаты}
\begin{table}[H]
\centering
\caption{Сравнение реализаций (матрица 5000x5000)}
\begin{tabular}{|l|c|c|}
\hline
\textbf{Технология} & \textbf{Ускорение} & \textbf{Эффективность} \\ \hline
Последовательная & 1x & 100\% \\ \hline
OpenMP (12 потоков) & 4.2x & 35\% \\ \hline
TBB & 3.8x & 32\% \\ \hline
STL & 3.5x & 29\% \\ \hline
MPI (2 узла) & 2.9x & 24\% \\ \hline
\end{tabular}
\end{table}

\subsection{Анализ}
\begin{itemize}
\item \textbf{OpenMP}: Максимальное ускорение достигнуто благодаря оптимизированному планировщику.
\item \textbf{TBB}: Хорошая масштабируемость на задачах с неравномерной нагрузкой.
\item \textbf{STL}: Ручное управление позволяет гибко настраивать балансировку.
\item \textbf{MPI}: Наибольшие накладные расходы из-за передачи данных между узлами.
\end{itemize}

\section{Заключение}
\begin{itemize}
\item Для десктопных систем (i5-12400F) оптимальны OpenMP и TBB.
\item MPI+STL подходит для распределенных задач, но требует оптимизации коммуникаций.
\item Ключевой фактор — минимизация синхронизации при работе с разреженными структурами.
\end{itemize}

\section{Список литературы}
\begin{enumerate}
\item Davis T.A. Direct Methods for Sparse Linear Systems. — SIAM, 2006.
\item Intel® oneAPI Threading Building Blocks Developer Guide. — 2023.
\item MPI Forum. MPI: A Message-Passing Interface Standard. — Version 4.0, 2021.
\end{enumerate}

\end{document}